{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify_videos\n",
    "\n",
    "* 適当に分類ルールを作成し歌動画か否かを分類します\n",
    "* 訓練データを用いて評価を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythonの基本ライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ファイル操作\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 機械学習\n",
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Jupyter上にHTMLを表示する\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全動画数: 44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Thumbnail</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>Duration</th>\n",
       "      <th>DurationOriginal</th>\n",
       "      <th>Description</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>DislikeCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hlwojkAO61A</td>\n",
       "      <td>戌神ころね</td>\n",
       "      <td>UChAnqc_AY5_I3Px5dig3X1Q</td>\n",
       "      <td>2020-08-23T04:38:18Z</td>\n",
       "      <td>早口言葉、噛んだら即終了！</td>\n",
       "      <td>https://i.ytimg.com/vi/hlwojkAO61A/hqdefault.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>359</td>\n",
       "      <td>PT5M59S</td>\n",
       "      <td>わん！\\n\\n前回→https://www.youtube.com/watch?v=BaYx...</td>\n",
       "      <td>145488</td>\n",
       "      <td>8448</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3uZof09cUlA</td>\n",
       "      <td>戌神ころね</td>\n",
       "      <td>UChAnqc_AY5_I3Px5dig3X1Q</td>\n",
       "      <td>2021-08-24T13:46:23Z</td>\n",
       "      <td>8位以下なら即終了・リベンジのリベンジ・エターナル・ファイナルラスト</td>\n",
       "      <td>https://i.ytimg.com/vi/3uZof09cUlA/hqdefault.jpg</td>\n",
       "      <td>20</td>\n",
       "      <td>375</td>\n",
       "      <td>PT6M15S</td>\n",
       "      <td>Play Game : Mario Kart 8 Deluxe ( switch )\\nタグ...</td>\n",
       "      <td>118973</td>\n",
       "      <td>6120</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   Name                 ChannelId                  Date  \\\n",
       "0  hlwojkAO61A  戌神ころね  UChAnqc_AY5_I3Px5dig3X1Q  2020-08-23T04:38:18Z   \n",
       "1  3uZof09cUlA  戌神ころね  UChAnqc_AY5_I3Px5dig3X1Q  2021-08-24T13:46:23Z   \n",
       "\n",
       "                                Title  \\\n",
       "0                       早口言葉、噛んだら即終了！   \n",
       "1  8位以下なら即終了・リベンジのリベンジ・エターナル・ファイナルラスト   \n",
       "\n",
       "                                          Thumbnail  CategoryId  Duration  \\\n",
       "0  https://i.ytimg.com/vi/hlwojkAO61A/hqdefault.jpg          24       359   \n",
       "1  https://i.ytimg.com/vi/3uZof09cUlA/hqdefault.jpg          20       375   \n",
       "\n",
       "  DurationOriginal                                        Description  \\\n",
       "0          PT5M59S  わん！\\n\\n前回→https://www.youtube.com/watch?v=BaYx...   \n",
       "1          PT6M15S  Play Game : Mario Kart 8 Deluxe ( switch )\\nタグ...   \n",
       "\n",
       "   ViewCount  LikeCount  DislikeCount  CommentCount  Label  \n",
       "0     145488       8448             0           202      0  \n",
       "1     118973       6120             0           313      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainから動画を取得する\n",
    "file_select = 'okakoro'\n",
    "# file_select = 'hololive'\n",
    "file_names = glob.glob('output/'+file_select+'/*')\n",
    "\n",
    "all_videos = pd.read_csv('output/train/'+file_select+'/videos.csv', index_col=0)\n",
    "# filtered_videos = filtered_videos.fillna('Nan')\n",
    "print(\"全動画数:\", all_videos.shape[0])\n",
    "all_videos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歌動画一覧を渡しフィルタの性能を評価\n",
    "def validation_filter(filtered_videos, all_videos):\n",
    "    pred_1 = filtered_videos.shape[0]\n",
    "    true_positive = filtered_videos[filtered_videos['Label']==1].shape[0]\n",
    "    false_positive = pred_1 - true_positive\n",
    "    \n",
    "    # 歌動画と予測されなかった動画を取り出す\n",
    "    all_ids = np.array(all_videos['Id'])\n",
    "    filtered_ids = np.array(filtered_videos['Id'])\n",
    "    not_filtered_ids = np.zeros(all_ids.size)\n",
    "    for i, ids in enumerate(all_ids):\n",
    "        if ids not in filtered_ids:\n",
    "            not_filtered_ids[i] = 1\n",
    "    not_filtered_ids = not_filtered_ids.astype(bool)\n",
    "    not_filtered_videos = all_videos[not_filtered_ids]\n",
    "    \n",
    "    pred_0 = not_filtered_videos.shape[0]\n",
    "    true_negative = not_filtered_videos[not_filtered_videos['Label']==0].shape[0]\n",
    "    false_negative = pred_0 - true_negative\n",
    "    # print(true_positive, false_positive, true_negative, false_negative)\n",
    "    return (true_positive + true_negative) / all_videos.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルールベースで分類\n",
    "以下の基準でルールを作り適当に分類\n",
    "* カテゴリによるフィルタリング\n",
    "* 単語によるフィルタリング\n",
    "* タグによるフィルタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "フィルタリング後のデータ数： 28\n",
      "Accuracy: 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# フィルタリング1: カテゴリにてフィルタリング\n",
    "######################################\n",
    "\n",
    "# 音楽、エンターテイメント、ゲーム動画以外を除外（何故かゲーム動画の中にも多く含まれていた）\n",
    "# https://so-zou.jp/web-app/tech/web-api/google/youtube/category.htm\n",
    "\n",
    "n = all_videos.shape[0]\n",
    "filtered_ids = np.zeros(n)\n",
    "categories = np.array(all_videos['CategoryId'])\n",
    "titles = np.array(all_videos['Title'])\n",
    "descs = np.array(all_videos['Description'])\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    if category not in [10, 20, 24]:\n",
    "        filtered_ids[i] -= 10000\n",
    "\n",
    "######################################\n",
    "# フィルタリング2: Title、Descriptionによるフィルタリング\n",
    "######################################\n",
    "\n",
    "# titleに\"歌ってみた\"などが入る動画は高い可能性で歌動画と判断\n",
    "title_posiwords = [\n",
    "    '歌ってみた', 'オリジナル', 'ORIGINAL', 'COVER', 'FEAT'\n",
    "]\n",
    "for i, title in enumerate(titles):\n",
    "    title_upper = title.upper()\n",
    "    for keyword in title_posiwords:\n",
    "        if keyword in title_upper:\n",
    "            filtered_ids[i] += 100\n",
    "\n",
    "# 逆に\"実況\"や\"アニメ\"など入っている場合は歌動画ではないと判断\n",
    "title_negawords = [\n",
    "    '実況', 'クロスフェード', 'アニメ', 'アカペラ'\n",
    "]\n",
    "for i, title in enumerate(titles):\n",
    "    title_upper = title.upper()\n",
    "    for keyword in title_negawords:\n",
    "        if keyword in title_upper:\n",
    "            filtered_ids[i] -= 100\n",
    "\n",
    "# descriptionに\"歌ってみた\"などが入る動画は高い可能性で歌動画と判断\n",
    "desc_keywords = [\n",
    "    '歌ってみた', '歌詞', '作詞', '作曲', '編曲', '原曲', '本家', '歌唱', 'ボーカル', 'ミックス', \n",
    "    'SONG', 'MUSIC', 'VOCAL', 'MIX', 'COMPOSER', 'LYRIC', '歌', '曲'\n",
    "]\n",
    "for i, desc in enumerate(descs):\n",
    "    desc_upper = desc.upper()\n",
    "    for keyword in desc_keywords:\n",
    "        if keyword in desc_upper:\n",
    "            filtered_ids[i] += 1\n",
    "\n",
    "filetered_videos = all_videos[filtered_ids > 1]\n",
    "print(\"フィルタリング後のデータ数：\", filetered_videos.shape[0])\n",
    "accuracy = validation_filter(filetered_videos, all_videos)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagはほぼ機能していないため除外\n",
    "######################################\n",
    "# フィルタリング3: Tagによるフィルタリング\n",
    "######################################\n",
    "\n",
    "# n = all_videos.shape[0]\n",
    "# tags = np.array(all_videos['Tags'])\n",
    "# filtered_ids = np.zeros(n)\n",
    "\n",
    "# for i, tag in enumerate(tags):\n",
    "#     tag = tag.replace('[', '')\n",
    "#     tag = tag.replace(']', '')\n",
    "#     tag = tag.replace('\\'', '')\n",
    "#     taglist = tag.split(', ')\n",
    "    \n",
    "#     if '歌ってみた' in taglist:\n",
    "#         filtered_ids[i] = 1\n",
    "\n",
    "# filetered_videos = all_videos[filtered_ids > 0]\n",
    "# print(\"フィルタリング後のデータ数：\", filetered_videos.shape[0])\n",
    "# accuracy = validation_filter(filetered_videos, all_videos)\n",
    "# print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSOを用いて分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# フィルタリング4: Title、Descriptionをone-hotベクトルに変換してLASSOで分類\n",
    "######################################\n",
    "\n",
    "# トークナイザの準備\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "# print(bert_sc.config) # 語彙数が32000であることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語分割\n",
    "\n",
    "# TitleとDescriptionの両方で作成\n",
    "max_length = 256 # 最大で512\n",
    "X, Y = [], []\n",
    "\n",
    "# DataFrameからrow毎に取り出す\n",
    "# input_idsのみで十分\n",
    "for i, row in all_videos.iterrows():\n",
    "    # text = row['Title']\n",
    "    text = row['Description']\n",
    "    # text = row['Title'] + row['Description']\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length, \n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids']\n",
    "    input_ids = np.unique(input_ids) # countは一旦無視してuniqueにする\n",
    "    input_ids = input_ids[input_ids>=5] # [PAD], [UNK], [CLS], [SEP], [MASK]を削除\n",
    "    \n",
    "    zeros = np.zeros(32000)\n",
    "    zeros[input_ids] = 1\n",
    "    zeros = np.append(zeros, i) # IDを可視化するための一時処理\n",
    "    X.append(zeros)\n",
    "    Y.append(row['Label'])\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVで正解率を評価\n",
    "def cross_validation(X, Y, k=5):\n",
    "    # XとYをシャッフル\n",
    "    X, Y = shuffle(X, Y, random_state=0)\n",
    "    \n",
    "    # XとYをk分割\n",
    "    n = X.shape[0]\n",
    "    X_devs, Y_devs = [], []\n",
    "    for i in range(k):\n",
    "        if i != k-1:\n",
    "            X_dev, Y_dev = X[i*(n//5):(i+1)*(n//5)], Y[i*(n//5):(i+1)*(n//5)]\n",
    "        else:\n",
    "            X_dev, Y_dev = X[i*(n//5):], Y[i*(n//5):]\n",
    "        X_devs.append(X_dev)\n",
    "        Y_devs.append(Y_dev)\n",
    "        \n",
    "    # 1つをvalidation, 1つをテストとしてテスト誤差を計算する\n",
    "    test_accuracy = 0\n",
    "    for i in range(k):\n",
    "        print('k-cross-validation :', i+1, '/', k)\n",
    "        X_train_tmp, Y_train_tmp = [], []\n",
    "        for j in range(k-2):\n",
    "            X_train_tmp.append(X_devs[(i+j)%k])\n",
    "            Y_train_tmp.append(Y_devs[(i+j)%k])\n",
    "        X_train = np.concatenate(X_train_tmp)\n",
    "        Y_train = np.concatenate(Y_train_tmp)\n",
    "        X_val, Y_val = X_devs[(i+k-2)%k], Y_devs[(i+k-2)%k]\n",
    "        X_test, Y_test = X_devs[(i+k-1)%k], Y_devs[(i+k-1)%k]\n",
    "        \n",
    "        # logscaleでハイパラの候補を準備\n",
    "        params = np.logspace(-2, 0)\n",
    "        val_best = 0\n",
    "        test_best = 0\n",
    "        for param in params:\n",
    "            lr = LogisticRegression(penalty='l1', solver='liblinear', C=param)\n",
    "            lr.fit(X_train, Y_train)\n",
    "            \n",
    "            Y_pred = lr.predict(X_val)\n",
    "            if np.sum(Y_pred==Y_val) > val_best:\n",
    "                val_best = np.sum(Y_pred==Y_val)\n",
    "                # Accuracyも更新する\n",
    "                Y_pred = lr.predict(X_test)\n",
    "                test_best = np.sum(Y_pred==Y_test)\n",
    "            \n",
    "        test_accuracy += test_best    \n",
    "\n",
    "    return test_accuracy/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-cross-validation : 1 / 5\n",
      "k-cross-validation : 2 / 5\n",
      "k-cross-validation : 3 / 5\n",
      "k-cross-validation : 4 / 5\n",
      "k-cross-validation : 5 / 5\n",
      "CV Accuracy 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "# CVを実施\n",
    "print('CV Accuracy', cross_validation(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '様', '##@', '##u', '##又', 'ne', '_', 'Mi', 'おか', '猫', '##ゆ', '##ta', '##x', '##l', '本家', '##ko', '##ie', 'Mov', '##r', '##ay']\n",
      "['Mar', 'Game', 'ころ', 'Play', '##えもん', '##itch', '##am', '→', '##itter', '##io', 'tw', 'Twitter', '生', '##iko', '##ug', '#', '##神', '##e', 'in', '##ron']\n"
     ]
    }
   ],
   "source": [
    "# 頻度が高い単語を取り出す\n",
    "freq_word_ids = []\n",
    "for label in range(2):\n",
    "    freq_word_id = np.sum(X[Y == label], axis=0)\n",
    "    freq_word_ids.append(freq_word_id)\n",
    "    freq_word_rank = np.argsort(freq_word_id)[::-1]\n",
    "    # print(tokenizer.convert_ids_to_tokens(freq_word_rank[0:20]))\n",
    "\n",
    "# 特定のクラスでのみ頻度が高い単語を取り出す\n",
    "spec_word_ids = freq_word_ids[1] - freq_word_ids[0]\n",
    "spec_word_rank = np.argsort(spec_word_ids)[::-1]\n",
    "print(tokenizer.convert_ids_to_tokens(spec_word_rank[:20]))\n",
    "print(tokenizer.convert_ids_to_tokens(spec_word_rank[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84059914 -0.64827974 -0.56814835 -0.20505461 -0.15746338]\n",
      "['##e', '##ok', '##w', ')', 'な']\n",
      "[2.47054917 0.94155783 0.         0.         0.        ]\n",
      "['オリジナル', '曲', '##巽', '日程', 'マーティン']\n"
     ]
    }
   ],
   "source": [
    "# 全データを使って学習し、パラメータの重みから重要な単語を取り出す\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "# X_train, Y_train = shuffle(X, Y, random_state=0)\n",
    "\n",
    "# IDを可視化するための一時処理\n",
    "X_train = X_train.T[0:32000].T\n",
    "\n",
    "# ロジスティック回帰分析\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear', C=1.0) # ロジスティック回帰モデルのインスタンスを作成\n",
    "lr.fit(X_train, Y_train) # ロジスティック回帰モデルの重みを学習\n",
    "\n",
    "# 重みを確認\n",
    "w = lr.coef_[0]\n",
    "print(np.sort(w)[0:5])\n",
    "print(tokenizer.convert_ids_to_tokens(np.argsort(w)[0:5]))\n",
    "\n",
    "print(np.sort(w)[::-1][0:5])\n",
    "print(tokenizer.convert_ids_to_tokens(np.argsort(w)[::-1][0:5]))\n",
    "\n",
    "# 予測\n",
    "# IDを可視化するための一時処理\n",
    "# X_test = X_test.T[0:32000].T\n",
    "# Y_pred = lr.predict(X_test)\n",
    "# print(np.sum(Y_pred==Y_test), '/', Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_html_test(videos, predict, idxs, top_n=10):\n",
    "    html = '<h1>動画一覧を表示</h1>'\n",
    "    html += '<div style=\"float:left;\">'\n",
    "    \n",
    "    label0_count, label1_count = 0, 0\n",
    "    label0_html, label1_html = '', ''\n",
    "\n",
    "    for i in range(len(predict)):\n",
    "        idx = idxs[i]\n",
    "        label = int(predict[i])\n",
    "        if label == 0:\n",
    "            if label0_count < top_n:\n",
    "                if (label0_count) % (top_n/2) == 0:\n",
    "                    label0_html += '<br>'\n",
    "                label0_html += ('<img src=\"'+np.array(videos['Thumbnail'])[idx] +' \"alt=\"取得できませんでした\" width=\"150\">')\n",
    "                label0_count += 1\n",
    "        elif label == 1:\n",
    "            if label1_count < top_n:\n",
    "                if (label1_count) % (top_n/2) == 0:\n",
    "                    label1_html += '<br>'\n",
    "                label1_html += ('<img src=\"'+np.array(videos['Thumbnail'])[idx] +' \"alt=\"取得できませんでした\" width=\"150\">')\n",
    "                label1_count += 1\n",
    "        if label0_count == top_n and label1_count == top_n:\n",
    "            break\n",
    "\n",
    "    html += ('<h2>非歌動画</h2>' + label0_html + '<br>')\n",
    "    html += ('<h2>歌動画</h2>' + label1_html + '<br>')\n",
    "    html += '</div>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>動画一覧を表示</h1><div style=\"float:left;\"><h2>非歌動画</h2><br><img src=\"https://i.ytimg.com/vi/RfUWTuwb_S8/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><img src=\"https://i.ytimg.com/vi/Dp4-sTORecc/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><img src=\"https://i.ytimg.com/vi/lJHaTKM1pIY/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><br><h2>歌動画</h2><br><img src=\"https://i.ytimg.com/vi/eBjPG7oxqFU/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><img src=\"https://i.ytimg.com/vi/gFVC0p4lknw/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><img src=\"https://i.ytimg.com/vi/kP08-jP1-7Y/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><img src=\"https://i.ytimg.com/vi/7jk8e94Cr7U/hqdefault.jpg \"alt=\"取得できませんでした\" width=\"150\"><br></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 良かった方法でランキングにして可視化\n",
    "\n",
    "# IDを可視化するための一時処理\n",
    "video_ids = X_test.T[32000].astype(int)\n",
    "X_test_ = X_test.T[0:32000].T\n",
    "Y_pred = lr.predict(X_test_)\n",
    "\n",
    "HTML(output_html_test(all_videos, Y_pred, video_ids, top_n=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-youtube",
   "language": "python",
   "name": "study-youtube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
